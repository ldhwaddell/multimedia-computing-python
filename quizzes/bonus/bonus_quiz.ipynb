{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1A\n",
    "\n",
    "Reads a script file (friends_pilot.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function also used in Programming Quiz 5\n",
    "def tokenize_text(text):\n",
    "    return np.array(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file\n",
    "with open(\"given_files/friends_pilot.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Tokenize it\n",
    "tokens = tokenize_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1B\n",
    "\n",
    "Removes non-words and stopwords\n",
    "Suggested: monica paul chandler joey phoebe ross rachel scene n't 's 're 'm na ca gon 'll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function also used in Programming Quiz 5\n",
    "def remove_non_words(word_tokens):\n",
    "    tokens_without_non_words = [\n",
    "        word for word in word_tokens if re.search(r\"[a-zA-Z]\", word)\n",
    "    ]\n",
    "    return np.array(tokens_without_non_words)\n",
    "\n",
    "\n",
    "# Helper function also used in Programming Quiz 5\n",
    "def remove_stop_words(tokens_without_non_words, stop_words):\n",
    "    tokens_without_stop_words = []\n",
    "    for word in tokens_without_non_words:\n",
    "        if word in stop_words or word.lower() in stop_words:\n",
    "            continue\n",
    "\n",
    "        tokens_without_stop_words.append(word)\n",
    "    return np.array(tokens_without_stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-words\n",
    "tokens_without_nonwords = remove_non_words(tokens)\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "# Additional words to remove identified in assignment description and other weird ones\n",
    "additional_words = [\n",
    "    \"Monica\",\n",
    "    \"Chandler\",\n",
    "    \"Joey\",\n",
    "    \"Richard\",\n",
    "    \"Phoebe\",\n",
    "    \"Ross\",\n",
    "    \"Rachel\",\n",
    "    \"Thompson\",\n",
    "    \"Elizabeth\",\n",
    "    \"Paul\",\n",
    "    \"'ll\",\n",
    "    \"n't\",\n",
    "    \"'s\",\n",
    "    \"'re\",\n",
    "    \"'m\",\n",
    "    \"na\",\n",
    "    \"gon\",\n",
    "    \"ca\",\n",
    "    \"I\",\n",
    "    \"[\",\n",
    "    \"]\",\n",
    "    \"Scene\",\n",
    "]\n",
    "\n",
    "# Add additional words to stopwords\n",
    "stop_words = stop_words + additional_words\n",
    "\n",
    "tokens_without_non_and_stop_words = remove_stop_words(\n",
    "    tokens_without_nonwords, stop_words\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Create a BoW with the top 20 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate BoW\n",
    "def generate_BoW(tokens):\n",
    "    counts = Counter(tokens)\n",
    "\n",
    "    # Sort them based on counts high to low\n",
    "    sorted_word_counts = sorted(counts.items(), key=lambda word: word[1], reverse=True)\n",
    "\n",
    "    return sorted_word_counts[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Oh', 29), ('know', 28), ('like', 21), ('got', 17), ('cut', 16), ('get', 15), ('right', 13), ('go', 13), ('Okay', 12), ('God', 11), ('Well', 11), ('think', 11), ('want', 10), ('date', 9), ('back', 9), ('look', 9), ('okay', 9), ('coffee', 9), ('mean', 9), ('Yeah', 9)]\n"
     ]
    }
   ],
   "source": [
    "BoW = generate_BoW(tokens_without_non_and_stop_words)\n",
    "\n",
    "print(BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "- Generate a Huffman tree and assign codes to them\n",
    "- Prints out the codes in a nice format in the descending order of their frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was taken from \"rec_nov20_2023\" and\n",
    "# https://www.programiz.com/dsa/huffman-coding\n",
    "# It is slightly modified so that it works with python and numpy strings\n",
    "class TreeNode(object):\n",
    "    def __init__(self, left=None, right=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def children(self):\n",
    "        return (self.left, self.right)\n",
    "\n",
    "    def nodes(self):\n",
    "        return (self.left, self.right)\n",
    "\n",
    "\n",
    "# Function to generate the nodes from the Bag of Words\n",
    "def generate_nodes(BoW):\n",
    "    BoW_copy = list(BoW)\n",
    "    while len(BoW_copy) > 1:\n",
    "        key1, c1 = BoW_copy.pop()\n",
    "        key2, c2 = BoW_copy.pop()\n",
    "\n",
    "        node = TreeNode(key1, key2)\n",
    "        BoW_copy.append((node, c1 + c2))\n",
    "\n",
    "        BoW_copy = sorted(BoW_copy, key=lambda x: x[1], reverse=True)\n",
    "    return BoW_copy\n",
    "\n",
    "\n",
    "# Main function implementing huffman coding\n",
    "def huffman_code_tree(node, left=True, binString=\"\"):\n",
    "    # Play nice with numpy\n",
    "    if type(node) in [str, np.str_]:\n",
    "        return {node: binString}\n",
    "\n",
    "    (l, r) = node.children()\n",
    "    d = dict()\n",
    "    d.update(huffman_code_tree(l, True, binString + \"0\"))\n",
    "    d.update(huffman_code_tree(r, False, binString + \"1\"))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word       Bits         Freq\n",
      "----------------------------\n",
      "Oh         010            29\n",
      "know       001            28\n",
      "like       1101           21\n",
      "got        1000           17\n",
      "cut        0111           16\n",
      "get        0110           15\n",
      "right      0001           13\n",
      "go         0000           13\n",
      "Okay       11111          12\n",
      "God        11110          11\n",
      "Well       11101          11\n",
      "think      11100          11\n",
      "want       11001          10\n",
      "date       11000           9\n",
      "back       10011           9\n",
      "look       10010           9\n",
      "okay       10101           9\n",
      "coffee     10100           9\n",
      "mean       10111           9\n",
      "Yeah       10110           9\n"
     ]
    }
   ],
   "source": [
    "nodes = generate_nodes(BoW)\n",
    "\n",
    "huffman_code = huffman_code_tree(nodes[0][0])\n",
    "\n",
    "print(\"Word       Bits         Freq\")\n",
    "print(\"----------------------------\")\n",
    "for word, frequency in BoW:\n",
    "    bits = huffman_code[word]\n",
    "    print(f\"{word:8}   {bits:10}   {frequency:4}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
